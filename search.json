[
  {
    "objectID": "example_3.html",
    "href": "example_3.html",
    "title": "Example #3",
    "section": "",
    "text": "Some examples of non-proprietary analysis.\nWork in progress"
  },
  {
    "objectID": "example_1.html",
    "href": "example_1.html",
    "title": "Example #1",
    "section": "",
    "text": "A version of the pbmc3k tutorial from the Satija Lab, together with my own notes, code changes and extensions. The tutorial was re-coded in RStudio as Quarto project, ran on a laptop and published to my github. The focus is on software and data understanding whilst producing the same results. In following example(s), I plan to adjust some parameters to look at the stability of the result with respect to these.\n\nStudy pbmc3k\n\nPeripheral Blood Mononuclear Cells (PBMC)\n10X Genomics\n2,700 single cells\nsequenced on Illumina NextSeq 500"
  },
  {
    "objectID": "example_1.html#overview",
    "href": "example_1.html#overview",
    "title": "Example #1",
    "section": "",
    "text": "A version of the pbmc3k tutorial from the Satija Lab, together with my own notes, code changes and extensions. The tutorial was re-coded in RStudio as Quarto project, ran on a laptop and published to my github. The focus is on software and data understanding whilst producing the same results. In following example(s), I plan to adjust some parameters to look at the stability of the result with respect to these.\n\nStudy pbmc3k\n\nPeripheral Blood Mononuclear Cells (PBMC)\n10X Genomics\n2,700 single cells\nsequenced on Illumina NextSeq 500"
  },
  {
    "objectID": "example_1.html#background",
    "href": "example_1.html#background",
    "title": "Example #1",
    "section": "Background",
    "text": "Background\n\nHighly Parallel Genome-wide Expression Profiling of Individual Cells Using Nanoliter Droplets\n\nCell, 2015\nDrop-Seq barcoding schematic\n\nprimer bead, sequence domains\n\n|— PCR —| — cell barcode —| — UMI — | — polyT27 — |\nUMI: Unique Molecular IDs region\n\n\nPaired end reads"
  },
  {
    "objectID": "example_1.html#import-data",
    "href": "example_1.html#import-data",
    "title": "Example #1",
    "section": "Import Data",
    "text": "Import Data\n\nLibraries\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(Seurat)\n\nAttaching SeuratObject\n\n\n'SeuratObject' was built under R 4.3.0 but the current version is\n4.3.1; it is recomended that you reinstall 'SeuratObject' as the ABI\nfor R may have changed\n\n\nSeurat v4 was just loaded with SeuratObject v5; disabling v5 assays and\nvalidation routines, and ensuring assays work in strict v3/v4\ncompatibility mode\n\nlibrary(patchwork)\n\n# Define a constant by convention to identify this example\n# To be used as part of filenames when saving objects\n# Example Number\nEGN &lt;- '_Eg1'\n\n\n# Data downloaded into git repo \n#   29 MB for barcodes, genes and matrix files \n# NB: these data are already filtered for barcodes within data\n# unfiltered would include all possible barcodes \n# (all synthesized barcodes or all theoretical possibilites given\n# a certain n of synthesis cycles? would need to delve into bead synthesis here)\ndata_dir &lt;- \"./filtered_gene_bc_matrices/hg19/\"\nlist.files(path = data_dir)\n\n[1] \"barcodes.tsv\" \"genes.tsv\"    \"matrix.mtx\"  \n\n\n\n\nIndependent look at data files\n\n# indepenedant look at files to be grounded..\n# TSVs\ngenes_tsv &lt;- read.csv(paste0(data_dir, \"genes.tsv\"), sep = \"\\t\", header = FALSE)\npaste0(\"n genes: \",nrow(genes_tsv), \". Some rows...\")\n\n[1] \"n genes: 32738. Some rows...\"\n\nhead(genes_tsv)\n\n               V1           V2\n1 ENSG00000243485   MIR1302-10\n2 ENSG00000237613      FAM138A\n3 ENSG00000186092        OR4F5\n4 ENSG00000238009 RP11-34P13.7\n5 ENSG00000239945 RP11-34P13.8\n6 ENSG00000237683   AL627309.1\n\nrm(genes_tsv)\n\nbarcode_tsv &lt;- read.csv(paste0(data_dir, \"barcodes.tsv\"), sep = \"\\t\", header = FALSE)\npaste0(\"n cell barcodes: \", nrow(barcode_tsv), \". Some rows...\")\n\n[1] \"n cell barcodes: 2700. Some rows...\"\n\nhead(barcode_tsv)\n\n                V1\n1 AAACATACAACCAC-1\n2 AAACATTGAGCTAC-1\n3 AAACATTGATCAGC-1\n4 AAACCGTGCTTCCG-1\n5 AAACCGTGTATGCG-1\n6 AAACGCACTGGTAC-1\n\nrm(barcode_tsv)\n\n# Sample of matrix \n# line 3 is n genes, n cells (barcodes), n lines of data  \n# line &gt;3 gene\n# gene_id barcode_id, umi_count\nreadLines(paste0(data_dir, \"matrix.mtx\"),10)\n\n [1] \"%%MatrixMarket matrix coordinate real general\"\n [2] \"%\"                                            \n [3] \"32738 2700 2286884\"                           \n [4] \"32709 1 4\"                                    \n [5] \"32707 1 1\"                                    \n [6] \"32706 1 10\"                                   \n [7] \"32704 1 1\"                                    \n [8] \"32703 1 5\"                                    \n [9] \"32702 1 6\"                                    \n[10] \"32700 1 10\"                                   \n\n# we can see sparsity from these numbers\n(1 - (2286884 / (32738 * 2700))) * 100\n\n[1] 97.41281\n\n# Sparse Matrix is a \"dgTMatrix\"\nsparse_m &lt;- Matrix::readMM(paste0(data_dir, \"matrix.mtx\"))\n#class(sparse_m)\nn_row_genes &lt;- nrow(sparse_m)\nn_col_cells &lt;- ncol(sparse_m)\nsparsity &lt;- round( sum(sparse_m == 0) / length(sparse_m)  * 100,2)\ndgTMatrix_summary &lt;- paste0(\"n_row_genes: \", n_row_genes, \n                            \", n_col_cells: \", n_col_cells, \n                            \", sparsity: \", sparsity, \" %\")\ndgTMatrix_summary\n\n[1] \"n_row_genes: 32738, n_col_cells: 2700, sparsity: 97.41 %\"\n\nrm(sparse_m)\n\n\n\nStandard import\n\n# creates dgCMatrix of all 3 files content\npbmc.data &lt;- Read10X(data.dir = data_dir)\n# class(pbmc.data)\n\n# Seurat object with the raw (non-normalized data).\n\n# Keep genes expressed in at least min.cells\n# Include cells where at least min.features are detected\npbmc &lt;- CreateSeuratObject(counts = pbmc.data, \n                           project = \"pbmc3k\", \n                           min.cells = 3, \n                           min.features = 200)\n\nWarning: Feature names cannot have underscores ('_'), replacing with dashes\n('-')\n\nWarning: Feature names cannot have underscores ('_'), replacing with dashes\n('-')\n\n# Seurat object has reduced number of features (genes)\n# and possiblly samples (cells) with harsher paremeters\n# min.cells = 50, min.features = 400\npbmc\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 0 variable features)\n 2 layers present: counts, data"
  },
  {
    "objectID": "example_1.html#pre-processing",
    "href": "example_1.html#pre-processing",
    "title": "Example #1",
    "section": "Pre-processing",
    "text": "Pre-processing\nBlockquote:\n\nSeurat allows you to easily explore QC metrics and filter cells based on any user-defined criteria. A few QC metrics commonly used by the community include\n\nThe number of unique genes detected in each cell.\n\nLow-quality cells or empty droplets will often have very few genes\nCell doublets or multiplets may exhibit an aberrantly high gene count\n\nSimilarly, the total number of molecules detected within a cell (correlates strongly with unique genes)\nThe percentage of reads that map to the mitochondrial genome\n\nLow-quality / dying cells often exhibit extensive mitochondrial contamination\nWe calculate mitochondrial QC metrics with the PercentageFeatureSet() function, which calculates the percentage of counts originating from a set of features\nWe use the set of all genes starting with MT- as a set of mitochondrial genes\n\n\n\n\nMeta data stash, calculations and basis for filtering\n\n# Stashing meta data\nhead(pbmc@meta.data, 5)\n\n                 orig.ident nCount_RNA nFeature_RNA\nAAACATACAACCAC-1     pbmc3k       2419          779\nAAACATTGAGCTAC-1     pbmc3k       4903         1352\nAAACATTGATCAGC-1     pbmc3k       3147         1129\nAAACCGTGCTTCCG-1     pbmc3k       2639          960\nAAACCGTGTATGCG-1     pbmc3k        980          521\n\n# The [[ operator can add columns to object metadata. \n# In this case the % mitochondrial DNA based on syntax of gene naming\n# \npbmc[[\"percent.mt\"]] &lt;- PercentageFeatureSet(pbmc, pattern = \"^MT-\")\n\nhead(pbmc@meta.data, 5)\n\n                 orig.ident nCount_RNA nFeature_RNA percent.mt\nAAACATACAACCAC-1     pbmc3k       2419          779  3.0177759\nAAACATTGAGCTAC-1     pbmc3k       4903         1352  3.7935958\nAAACATTGATCAGC-1     pbmc3k       3147         1129  0.8897363\nAAACCGTGCTTCCG-1     pbmc3k       2639          960  1.7430845\nAAACCGTGTATGCG-1     pbmc3k        980          521  1.2244898\n\n\nThe MT- genes from genes.csv from a bash shell grep. Sure there is a way to get the same from Seurat object.\n\n# bash grep\ngrep '\\tMT-' ./filtered_gene_bc_matrices/hg19/genes.tsv \n\nENSG00000198888 MT-ND1\nENSG00000198763 MT-ND2\nENSG00000198804 MT-CO1\nENSG00000198712 MT-CO2\nENSG00000228253 MT-ATP8\nENSG00000198899 MT-ATP6\nENSG00000198938 MT-CO3\nENSG00000198840 MT-ND3\nENSG00000212907 MT-ND4L\nENSG00000198886 MT-ND4\nENSG00000198786 MT-ND5\nENSG00000198695 MT-ND6\nENSG00000198727 MT-CYB\n\n\n\n# Visualize QC metrics as a violin plot\nVlnPlot(pbmc, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"),\n        ncol = 3)\n\n\n\n\n\n# FeatureScatter is typically used to visualize feature-feature relationships \n# but can be used for anything calculated by the object, \n# i.e. columns in object metadata, PC scores etc.\n\nplot1 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\")\nplot2 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\")\nplot1 + plot2\n\n\n\n\n\n\nFiltering\nSome “exceptions” are dealt with at this stage\n\nA high ratio of mitochondrial DNA:nuclear DNA is typical of a dead or broken cell\nMultiple cells per drop is atypical but they can be picked up by high number of RNA counts\nEmpties are drops without intact cells but produce signal due to background RNA molecules from lyzed cells: they are filtered by having low gene (feature) count but that was already done in this case when the data was imported (see earlier)\nThere can be other issues e.g. barcode synthesis errors. Need to fix barcode/remove cell.\nThis filtering is at least kingdom specific - think of plant cells and chloroplast RNA, guard cells and endoreduplication….and rapidly dividing cultures of yeast and microbial cells that at the population level partly 2n\n\n\n# apply filters and overwrite the object!\npbmc &lt;- subset(pbmc, subset = nFeature_RNA &gt; 200 & \n                 nFeature_RNA &lt; 2500 & percent.mt &lt; 5)\n\n# what was the point of storing meta data?!\n# \n# It's OK, this meta-data is retained\n\nhead(pbmc@meta.data, 5)\n\n                 orig.ident nCount_RNA nFeature_RNA percent.mt\nAAACATACAACCAC-1     pbmc3k       2419          779  3.0177759\nAAACATTGAGCTAC-1     pbmc3k       4903         1352  3.7935958\nAAACATTGATCAGC-1     pbmc3k       3147         1129  0.8897363\nAAACCGTGCTTCCG-1     pbmc3k       2639          960  1.7430845\nAAACCGTGTATGCG-1     pbmc3k        980          521  1.2244898\n\n# And we can see clearly the effect of filtering\nplot1 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\")\nplot2 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\")\nplot1 + plot2\n\n\n\n\nRemember nFeature_RNA is the number of detected genes and the nCount_RNA is the total counts per drop (after filtering that should now be per single cell though in the case the one outlier point makes me wonder….seems like ~2000 features is the upper range….).\nAnother thought in passing: presumably alternative splice forms are mapped to the same gene as standard practice. Would like to look for an example of where splice forms are treated as separate entities which should be in principle possible."
  },
  {
    "objectID": "example_1.html#normalization",
    "href": "example_1.html#normalization",
    "title": "Example #1",
    "section": "Normalization",
    "text": "Normalization\n\nAfter removing unwanted cells from the data-set, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. Normalized values are stored in pbmc[[\"RNA\"]]@data.\n\n\n# \npbmc &lt;- NormalizeData(pbmc, normalization.method = \"LogNormalize\", \n                      scale.factor = 10000)\n\n# Show a small sample of data\n# Again, it's a sparse matrix \n# class(pbmc[[\"RNA\"]]@data)\nstr(pbmc[[\"RNA\"]]@data)\n\nFormal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n  ..@ i       : int [1:2238732] 29 73 80 148 163 184 186 227 229 230 ...\n  ..@ p       : int [1:2639] 0 779 2131 3260 4220 4741 5522 6304 7094 7626 ...\n  ..@ Dim     : int [1:2] 13714 2638\n  ..@ Dimnames:List of 2\n  .. ..$ : chr [1:13714] \"AL627309.1\" \"AP006222.2\" \"RP11-206L10.2\" \"RP11-206L10.9\" ...\n  .. ..$ : chr [1:2638] \"AAACATACAACCAC-1\" \"AAACATTGAGCTAC-1\" \"AAACATTGATCAGC-1\" \"AAACCGTGCTTCCG-1\" ...\n  ..@ x       : num [1:2238732] 1.64 1.64 2.23 1.64 1.64 ...\n  ..@ factors : list()\n\n# 10 rows, 3 columns\npbmc[[\"RNA\"]]@data[10:20,1:3]\n\n11 x 3 sparse Matrix of class \"dgCMatrix\"\n             AAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1\nHES4                        .         .                .       \nRP11-54O7.11                .         .                .       \nISG15                       .         .                1.429744\nAGRN                        .         .                .       \nC1orf159                    .         .                .       \nTNFRSF18                    .         1.625141         .       \nTNFRSF4                     .         .                .       \nSDF4                        .         .                1.429744\nB3GALT6                     .         .                .       \nFAM132A                     .         .                .       \nUBE2J2                      .         .                ."
  },
  {
    "objectID": "example_1.html#highly-variable-features",
    "href": "example_1.html#highly-variable-features",
    "title": "Example #1",
    "section": "Highly Variable Features",
    "text": "Highly Variable Features\n\nWe next calculate a subset of features that exhibit high cell-to-cell variation in the dataset (i.e, they are highly expressed in some cells, and lowly expressed in others). We and others have found that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.\nOur procedure in Seurat is described in detail here, and improves on previous versions by directly modeling the mean-variance relationship inherent in single-cell data, and is implemented in the FindVariableFeatures() function. By default, we return 2,000 features per dataset. These will be used in downstream analysis, like PCA.\n\n\npbmc &lt;- FindVariableFeatures(pbmc, selection.method = \"vst\", nfeatures = 2000)\n\n# vst: First, fits a line to the relationship of log(variance) and log(mean) using local \n# polynomial regression (loess). Then standardizes the feature values using the observed mean # and expected variance (given by the fitted line). Feature variance is then calculated on \n# the standardized values after clipping to a maximum (see clip.max parameter).\n# \n# Other selection methods available mean.var.plot (mvp) and dispersion (disp)\n#\n\n# Identify a number (n_top) of highly variable genes from \nn_top &lt;- 15\ntop_v_genes &lt;- head(VariableFeatures(pbmc), n_top)\ntop_v_genes\n\n [1] \"PPBP\"    \"LYZ\"     \"S100A9\"  \"IGLL5\"   \"GNLY\"    \"FTL\"     \"PF4\"    \n [8] \"FTH1\"    \"GNG11\"   \"S100A8\"  \"FCER1A\"  \"HLA-DRA\" \"CD74\"    \"CLU\"    \n[15] \"NKG7\"   \n\n# plot variable features with and without labels\nplot1 &lt;- VariableFeaturePlot(pbmc)\nplot2 &lt;- LabelPoints(plot = plot1, points = top_v_genes, repel = TRUE)\n\nWhen using repel, set xnudge and ynudge to 0 for optimal results\n\n# no need to view this, plot2 is better\n#plot1\nplot2 \n\nWarning: Transformation introduced infinite values in continuous x-axis"
  },
  {
    "objectID": "example_1.html#data-scaling",
    "href": "example_1.html#data-scaling",
    "title": "Example #1",
    "section": "Data Scaling",
    "text": "Data Scaling\nNormally i do a mean 0, standard dev 1 … but the method used here is more sophisticated.\n\nNext, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData() function:\n\nShifts the expression of each gene, so that the mean expression across cells is 0\nScales the expression of each gene, so that the variance across cells is 1\n\nThis step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate\n\nThe results of this are stored in pbmc[[\"RNA\"]]@scale.data\n\n\n\nall.genes &lt;- rownames(pbmc)\npbmc &lt;- ScaleData(pbmc, features = all.genes)\n\nCentering and scaling data matrix\n\n\nAnd there is a faster way…\n\nScaling is an essential step in the Seurat workflow, but only on genes that will be used as input to PCA. Therefore, the default in ScaleData() is only to perform scaling on the previously identified variable features (2,000 by default). To do this, omit the features argument in the previous function call, i.e.\npbmc &lt;- ScaleData(pbmc)\nYour PCA and clustering results will be unaffected. However, Seurat heatmaps (produced as shown below with DoHeatmap()) require genes in the heatmap to be scaled, to make sure highly-expressed genes don’t dominate the heatmap. To make sure we don’t leave any genes out of the heatmap later, we are scaling all genes in this tutorial.\n\nThis following section refers to the paper Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression Christoph Hafemeister & Rahul Satija (2019). I have this in paper notes as the method to deal with cell cycle genes. Interesting would be circadian cycle - I came across experimental data before that hadn’t considered this aspect in the experimental design!!\n\nHow can I remove unwanted sources of variation, as in Seurat v2?\nIn Seurat v2 we also use the ScaleData() function to remove unwanted sources of variation from a single-cell dataset. For example, we could ‘regress out’ heterogeneity associated with (for example) cell cycle stage, or mitochondrial contamination. These features are still supported in ScaleData() in Seurat v3, i.e.:\npbmc &lt;- ScaleData(pbmc, vars.to.regress = \"percent.mt\")\nHowever, particularly for advanced users who would like to use this functionality, we strongly recommend the use of our new normalization workflow, SCTransform(). The method is described in our paper, with a separate vignette using Seurat v3 here. As with ScaleData(), the function SCTransform() also includes a vars.to.regress parameter."
  },
  {
    "objectID": "example_1.html#linear-dimension-reduction",
    "href": "example_1.html#linear-dimension-reduction",
    "title": "Example #1",
    "section": "Linear Dimension Reduction",
    "text": "Linear Dimension Reduction\n\nRun PCA with the scaled data values\n\nby dafault a subset of genes corresponding to the variability calculation done previously in this workflow, although the subset is configurable at this stage\n\n# example of changing feature subset for calculation\npbmc &lt;- RunPCA(pbmc, features = VariableFeatures(object = pbmc))\n# but for now we just run with the default....\n\n# verbose is by dafault TRUE \n# it spits out a number of PCs (ndims.print = 1:5) \n# and genes (features) contributing to each PC (nfeatures.print = 30) \npbmc &lt;- RunPCA(pbmc, verbose = FALSE)\n# we could adjust those arguments or do the same more directly\n# by just jumping into the object's data structure\n#\n# the number to print \nn_features &lt;- 8\nprint(pbmc[[\"pca\"]], dims = 1:4, nfeatures = n_features)\n\nPC_ 1 \nPositive:  CST3, TYROBP, LST1, AIF1, FTL, FTH1, LYZ, FCN1 \nNegative:  MALAT1, LTB, IL32, IL7R, CD2, B2M, ACAP1, CD27 \nPC_ 2 \nPositive:  CD79A, MS4A1, TCL1A, HLA-DQA1, HLA-DQB1, HLA-DRA, LINC00926, CD79B \nNegative:  NKG7, PRF1, CST7, GZMB, GZMA, FGFBP2, CTSW, GNLY \nPC_ 3 \nPositive:  HLA-DQA1, CD79A, CD79B, HLA-DQB1, HLA-DPB1, HLA-DPA1, CD74, MS4A1 \nNegative:  PPBP, PF4, SDPR, SPARC, GNG11, NRGN, GP9, RGS18 \nPC_ 4 \nPositive:  HLA-DQA1, CD79B, CD79A, MS4A1, HLA-DQB1, CD74, HIST1H2AC, HLA-DPB1 \nNegative:  VIM, IL7R, S100A6, IL32, S100A8, S100A4, GIMAP7, S100A10 \n\n\n\n\nLook at the loadings matrix (V) and scores(U)\n\nV\n\n# Loadings\n# \n# best to use n * n_features, otherwise we can get plots that are biased to \n# either +ve or -ve contributions preseumably because nfeatures takes from a \n# ranked list disregarding sign\n#\n# e.g. see loadings of PC_4, no negatives plotted using n_features = 8\n#\nn_mulitplier = 3\nVizDimLoadings(pbmc, dims = 1:2, \n               reduction = \"pca\", \n               nfeatures = n_features * n_mulitplier)\n\n\n\nVizDimLoadings(pbmc, dims = 3:4, \n               reduction = \"pca\", \n               nfeatures = n_features * n_mulitplier)\n\n\n\n\n\n\nU\n\n# Dimplot has lots of options\nDimPlot(pbmc, reduction = \"pca\",  dims = c(1, 2))\n\n\n\nDimPlot(pbmc, reduction = \"pca\",  dims = c(2, 3))\n\n\n\n\n\n\n\nHeatmaps\nBlockquote:\n\nIn particular DimHeatmap() allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses. Both cells and features are ordered according to their PCA scores. Setting cells to a number plots the ‘extreme’ cells on both ends of the spectrum, which dramatically speeds plotting for large datasets. Though clearly a supervised analysis, we find this to be a valuable tool for exploring correlated feature sets.\n\n\nJust 1\n\n# as in quote above, \n# ordererd cells and genes according to PCA scores \n# \nn_cells &lt;- 300\nn_genes &lt;- 24\nDimHeatmap(pbmc, dims = 1, cells = n_cells, nfeatures = n_genes, balanced = TRUE)\n\n\n\n\n\n\nMany\n\n# balanced\nn_PC &lt;- 6\nplots &lt;- DimHeatmap(pbmc, dims = 1:n_PC, cells = n_cells, \n             nfeatures = n_genes, balanced = TRUE)\n\n\n\n\n\n\n\n\nif (0){\n  # for later...something not quite right with feature labels\n  # unbalanced \n  plots &lt;- DimHeatmap(pbmc, dims = 1:n_PC, cells = n_cells, \n             nfeatures = n_genes, balanced = FALSE)\n}"
  },
  {
    "objectID": "example_1.html#determine-dimensionality",
    "href": "example_1.html#determine-dimensionality",
    "title": "Example #1",
    "section": "Determine Dimensionality",
    "text": "Determine Dimensionality\n\nThe traditional way\n\n# how many PCs provide a useable amount of information to distinguish our cells? \nElbowPlot(pbmc)\n\n\n\n\n\n\nThe sophisticated way\n\nIn Macosko et al, we implemented a resampling test inspired by the JackStraw procedure. We randomly permute a subset of the data (1% by default) and rerun PCA, constructing a ‘null distribution’ of feature scores, and repeat this procedure. We identify ‘significant’ PCs as those who have a strong enrichment of low p-value features.\nThe JackStrawPlot() function provides a visualization tool for comparing the distribution of p-values for each PC with a uniform distribution (dashed line). ‘Significant’ PCs will show a strong enrichment of features with low p-values (solid curve above the dashed line). In this case it appears that there is a sharp drop-off in significance after the first 10-12 PCs.\n\n\nn_dims &lt;- 15\n# fast\nn_reps &lt;- 5\n# slow - my laptop is no server\n# n_reps &lt;- 100\npbmc &lt;- JackStraw(pbmc, num.replicate = n_reps)\npbmc &lt;- ScoreJackStraw(pbmc, dims = 1:n_dims)\nJackStrawPlot(pbmc, dims = 1:n_dims)\n\nWarning: Removed 22880 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nJackstrawPlot: 15 dimensions, 100 replicates. This version of the figure was computed in around 10 minutes on laptop. For the sake of speed the previous image was calculated with a small number of replicates.\n\n\n\n\n# we can set a variable to specifiy the number of PCs to use\n# and later perturb this with iterations to look into the stability of\n# the final result\n\nn_pcs_chosen &lt;- 10\n#n_pcs_chosen &lt;- 5\n#n_pcs_chosen &lt;- 15"
  },
  {
    "objectID": "example_1.html#cell-clustering",
    "href": "example_1.html#cell-clustering",
    "title": "Example #1",
    "section": "Cell Clustering",
    "text": "Cell Clustering\nBlockquote:\n\nSeurat v3 applies a graph-based clustering approach, building upon initial strategies in (Macosko et al). Importantly, the distance metric which drives the clustering analysis (based on previously identified PCs) remains the same. However, our approach to partitioning the cellular distance matrix into clusters has dramatically improved. Our approach was heavily inspired by recent manuscripts which applied graph-based clustering approaches to scRNA-seq data [SNN-Cliq, Xu and Su, Bioinformatics, 2015] and CyTOF data [PhenoGraph, Levine et al., Cell, 2015]. Briefly, these methods embed cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected ‘quasi-cliques’ or ‘communities’.\nAs in PhenoGraph, we first construct a KNN graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). This step is performed using the FindNeighbors() function, and takes as input the previously defined dimensionality of the dataset (first 10 PCs).\nTo cluster the cells, we next apply modularity optimization techniques such as the Louvain algorithm (default) or SLM [SLM, Blondel et al., Journal of Statistical Mechanics], to iteratively group cells together, with the goal of optimizing the standard modularity function. The FindClusters() function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters. We find that setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells. Optimal resolution often increases for larger datasets. The clusters can be found using the Idents() function.\n\n\n# create the K-nearest neighbor (KNN) graph of cells\npbmc &lt;- FindNeighbors(pbmc, dims = 1:n_pcs_chosen)\n\nComputing nearest neighbor graph\n\n\nComputing SNN\n\n# define clusters according to resolution\npbmc &lt;- FindClusters(pbmc, resolution = 0.5)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 2638\nNumber of edges: 95927\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8728\nNumber of communities: 9\nElapsed time: 0 seconds\n\n\n\n# Look at cluster IDs of the first 5 cells\n# In this case we have 9 levels (0 - 8)\n# The structure is the relation between cell barcode and the cluster (community) \nhead(Idents(pbmc), 5)\n\nAAACATACAACCAC-1 AAACATTGAGCTAC-1 AAACATTGATCAGC-1 AAACCGTGCTTCCG-1 \n               2                3                2                1 \nAAACCGTGTATGCG-1 \n               6 \nLevels: 0 1 2 3 4 5 6 7 8\n\n# Each cell that survived filtering above is represented \nlength(Idents(pbmc))\n\n[1] 2638\n\npbmc\n\nAn object of class Seurat \n13714 features across 2638 samples within 1 assay \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 dimensional reduction calculated: pca"
  },
  {
    "objectID": "example_1.html#non-linear-dimensional-reduction",
    "href": "example_1.html#non-linear-dimensional-reduction",
    "title": "Example #1",
    "section": "Non-Linear Dimensional Reduction",
    "text": "Non-Linear Dimensional Reduction\nBlockquote:\n\nSeurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets. The goal of these algorithms is to learn the underlying manifold of the data in order to place similar cells together in low-dimensional space. Cells within the graph-based clusters determined above should co-localize on these dimension reduction plots. As input to the UMAP and tSNE, we suggest using the same PCs as input to the clustering analysis.\n\n\n# UMAP\npbmc &lt;- RunUMAP(pbmc, dims = 1:n_pcs_chosen)\n\nWarning: The default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric\nTo use Python UMAP via reticulate, set umap.method to 'umap-learn' and metric to 'correlation'\nThis message will be shown once per session\n\n\n14:08:41 UMAP embedding parameters a = 0.9922 b = 1.112\n\n\n14:08:41 Read 2638 rows and found 10 numeric columns\n\n\n14:08:41 Using Annoy for neighbor search, n_neighbors = 30\n\n\n14:08:41 Building Annoy index with metric = cosine, n_trees = 50\n\n\n0%   10   20   30   40   50   60   70   80   90   100%\n\n\n[----|----|----|----|----|----|----|----|----|----|\n\n\n**************************************************|\n14:08:41 Writing NN index file to temp file /var/folders/zp/wn7hdby52ds73hv9g_dxlk380000gn/T//RtmpU758Ng/filee31b16b6faa9\n14:08:41 Searching Annoy index using 1 thread, search_k = 3000\n14:08:42 Annoy recall = 100%\n14:08:43 Commencing smooth kNN distance calibration using 1 thread with target n_neighbors = 30\n14:08:43 Initializing from normalized Laplacian + noise (using irlba)\n14:08:43 Commencing optimization for 500 epochs, with 105140 positive edges\n14:08:48 Optimization finished\n\nDimPlot(pbmc, reduction = \"umap\")\n\n\n\n# tSNE\npbmc &lt;- RunTSNE(pbmc, dims = 1:n_pcs_chosen)\nDimPlot(pbmc, reduction = \"tsne\")"
  },
  {
    "objectID": "example_1.html#check-point-the-object",
    "href": "example_1.html#check-point-the-object",
    "title": "Example #1",
    "section": "Check-Point The Object",
    "text": "Check-Point The Object\nNote that the pmbc can be saved and reloaded with the R base package function\n\n# Useful for code development.\n# Save the object at a point and reload it into the R console \n# e.g. for developing alternative reports in the next section \n# without having to run the pipeline right from the start\n# which can be slow\n\nsaveRDS_overwrite &lt;- function(file_path) {\n  if (file.exists(file_path)) {\n    file.remove(file_path)\n  } \n  saveRDS(pbmc, file = file_path)\n}\n\nfile_path &lt;- paste0(\"./seurat_object_checkpoints/pbmc_sw1\",EGN,\".rds\")\nsaveRDS_overwrite(file_path)\n\n# NB: Files produced by saveRDS (or serialize to a file connection) \n# are not suitable as an interchange format between machines\n\n# restore the object from disk\npbmc &lt;- readRDS(file_path)"
  },
  {
    "objectID": "example_1.html#cluster-biomarkers",
    "href": "example_1.html#cluster-biomarkers",
    "title": "Example #1",
    "section": "Cluster Biomarkers",
    "text": "Cluster Biomarkers\nDifferentially expressed genes between a given cluster and the cell population as a whole or as an alternative, select specific clusters\nBlockquote:\n\nSeurat can help you find markers that define clusters via differential expression. By default, it identifies positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers() automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells.\nThe min.pct argument requires a feature to be detected at a minimum percentage in either of the two groups of cells, and the thresh.test argument requires a feature to be differentially expressed (on average) by some amount between the two groups. You can set both of these to 0, but with a dramatic increase in time - since this will test a large number of features that are unlikely to be highly discriminatory. As another option to speed up these computations, max.cells.per.ident can be set. This will downsample each identity class to have no more cells than whatever this is set to. While there is generally going to be a loss in power, the speed increases can be significant and the most highly differentially expressed features will likely still rise to the top.\n\n\n# find all markers of cluster 2\ncluster2.markers &lt;- FindMarkers(pbmc, ident.1 = 2, min.pct = 0.25)\nhead(cluster2.markers, n = 5)\n\n            p_val avg_log2FC pct.1 pct.2    p_val_adj\nIL32 2.892340e-90  1.2013522 0.947 0.465 3.966555e-86\nLTB  1.060121e-86  1.2695776 0.981 0.643 1.453850e-82\nCD3D 8.794641e-71  0.9389621 0.922 0.432 1.206097e-66\nIL7R 3.516098e-68  1.1873213 0.750 0.326 4.821977e-64\nLDHB 1.642480e-67  0.8969774 0.954 0.614 2.252497e-63\n\n\n\n# find all markers distinguishing cluster 5 from clusters 0 and 3\ncluster5.markers &lt;- FindMarkers(pbmc, ident.1 = 5, \n                                ident.2 = c(0, 3), min.pct = 0.25)\nhead(cluster5.markers, n = 5)\n\n                      p_val avg_log2FC pct.1 pct.2     p_val_adj\nFCGR3A        8.246578e-205   4.261495 0.975 0.040 1.130936e-200\nIFITM3        1.677613e-195   3.879339 0.975 0.049 2.300678e-191\nCFD           2.401156e-193   3.405492 0.938 0.038 3.292945e-189\nCD68          2.900384e-191   3.020484 0.926 0.035 3.977587e-187\nRP11-290F20.3 2.513244e-186   2.720057 0.840 0.017 3.446663e-182\n\n\n\n# find markers for every cluster compared to all remaining cells, \n# report only the positive ones\npbmc.markers &lt;- FindAllMarkers(pbmc, only.pos = TRUE, \n                               min.pct = 0.25, logfc.threshold = 0.25)\n\nCalculating cluster 0\n\n\nCalculating cluster 1\n\n\nCalculating cluster 2\n\n\nCalculating cluster 3\n\n\nCalculating cluster 4\n\n\nCalculating cluster 5\n\n\nCalculating cluster 6\n\n\nCalculating cluster 7\n\n\nCalculating cluster 8\n\npbmc.markers %&gt;%\n    group_by(cluster) %&gt;%\n    slice_max(n = 2, order_by = avg_log2FC)\n\n# A tibble: 18 × 7\n# Groups:   cluster [9]\n       p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene    \n       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;   \n 1 9.57e- 88       1.36 0.447 0.108 1.31e- 83 0       CCR7    \n 2 3.75e-112       1.09 0.912 0.592 5.14e-108 0       LDHB    \n 3 0               5.57 0.996 0.215 0         1       S100A9  \n 4 0               5.48 0.975 0.121 0         1       S100A8  \n 5 1.06e- 86       1.27 0.981 0.643 1.45e- 82 2       LTB     \n 6 2.97e- 58       1.23 0.42  0.111 4.07e- 54 2       AQP3    \n 7 0               4.31 0.936 0.041 0         3       CD79A   \n 8 9.48e-271       3.59 0.622 0.022 1.30e-266 3       TCL1A   \n 9 5.61e-202       3.10 0.983 0.234 7.70e-198 4       CCL5    \n10 7.25e-165       3.00 0.577 0.055 9.95e-161 4       GZMK    \n11 3.51e-184       3.31 0.975 0.134 4.82e-180 5       FCGR3A  \n12 2.03e-125       3.09 1     0.315 2.78e-121 5       LST1    \n13 3.13e-191       5.32 0.961 0.131 4.30e-187 6       GNLY    \n14 7.95e-269       4.83 0.961 0.068 1.09e-264 6       GZMB    \n15 1.48e-220       3.87 0.812 0.011 2.03e-216 7       FCER1A  \n16 1.67e- 21       2.87 1     0.513 2.28e- 17 7       HLA-DPB1\n17 1.92e-102       8.59 1     0.024 2.63e- 98 8       PPBP    \n18 9.25e-186       7.29 1     0.011 1.27e-181 8       PF4     \n\n\nBlockquote:\n\nSeurat has several tests for differential expression which can be set with the test.use parameter (see our DE vignette for details). For example, the ROC test returns the ‘classification power’ for any individual marker (ranging from 0 - random, to 1 - perfect).\n\n\ncluster0.markers &lt;- FindMarkers(pbmc, ident.1 = 0, \n                                logfc.threshold = 0.25, \n                                test.use = \"roc\", only.pos = TRUE)\n\nhead(cluster0.markers,20)\n\n       myAUC  avg_diff power avg_log2FC pct.1 pct.2\nRPS12  0.827 0.5059247 0.654  0.7298951 1.000 0.991\nRPS6   0.826 0.4762402 0.652  0.6870694 1.000 0.995\nRPS27  0.824 0.5047203 0.648  0.7281575 0.999 0.992\nRPL32  0.821 0.4294911 0.642  0.6196246 0.999 0.995\nRPS14  0.811 0.4334133 0.622  0.6252832 1.000 0.994\nRPS25  0.803 0.5196163 0.606  0.7496479 0.997 0.975\nRPL31  0.798 0.5227603 0.596  0.7541837 0.997 0.964\nRPL9   0.797 0.5230934 0.594  0.7546643 0.997 0.971\nRPL13  0.792 0.3893890 0.584  0.5617696 1.000 0.996\nRPL3   0.788 0.4200060 0.576  0.6059406 0.997 0.995\nRPS3   0.788 0.4104851 0.576  0.5922049 1.000 0.994\nRPS3A  0.787 0.5461948 0.574  0.7879925 0.997 0.975\nRPL30  0.785 0.4606356 0.570  0.6645567 1.000 0.980\nLDHB   0.784 0.7521034 0.568  1.0850559 0.912 0.592\nRPL21  0.783 0.4576652 0.566  0.6602714 0.997 0.991\nRPS15A 0.782 0.4417193 0.564  0.6372663 0.997 0.983\nRPLP2  0.776 0.4113912 0.552  0.5935120 1.000 0.990\nRPS27A 0.770 0.5076242 0.540  0.7323469 0.994 0.967\nRPS13  0.769 0.4814302 0.538  0.6945569 0.985 0.962\nEEF1A1 0.769 0.3662114 0.538  0.5283314 0.994 0.991\n\n\nBlockquote:\n\nWe include several tools for visualizing marker expression. VlnPlot() (shows expression probability distributions across clusters), and FeaturePlot() (visualizes feature expression on a tSNE or PCA plot) are our most commonly used visualizations. We also suggest exploring RidgePlot(), CellScatter(), and DotPlot() as additional methods to view your dataset.\n\n\nVlnPlot(pbmc, features = c(\"MS4A1\", \"CD79A\"))\n\n\n\n\n\nVlnPlot(pbmc, features = c(\"NKG7\", \"PF4\"), slot = \"counts\", log = TRUE)\n\n\n\n\n\n# the 3 x 3 grid did not look clear on my laptop\n# try by 2 \nFeaturePlot(pbmc, features = c(\"MS4A1\", \"GNLY\"))\n\n\n\nFeaturePlot(pbmc, features = c(\"CD3E\", \"CD14\"))\n\n\n\nFeaturePlot(pbmc, features = c(\"FCER1A\", \"FCGR3A\"))\n\n\n\nFeaturePlot(pbmc, features = c(\"LYZ\", \"PPBP\"))\n\n\n\nFeaturePlot(pbmc, features = c(\"CD8A\"))\n\n\n\n\nBlockquote:\n\nDoHeatmap() generates an expression heatmap for given cells and features. In this case, we are plotting the top 20 markers (or all markers if less than 20) for each cluster.\n\n\n# the default was 10 \n# the heatmap is hard to read with so many markers\n# would need to produce a larger version with high label resolution \npbmc.markers %&gt;%\n    group_by(cluster) %&gt;%\n    top_n(n = 5, wt = avg_log2FC) -&gt; top_n\n\nhead(top_n,10)\n\n# A tibble: 10 × 7\n# Groups:   cluster [2]\n       p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene     \n       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;    \n 1 3.75e-112      1.09  0.912 0.592 5.14e-108 0       LDHB     \n 2 9.57e- 88      1.36  0.447 0.108 1.31e- 83 0       CCR7     \n 3 1.35e- 51      1.08  0.342 0.103 1.86e- 47 0       LEF1     \n 4 2.81e- 44      0.951 0.443 0.185 3.85e- 40 0       PIK3IP1  \n 5 6.27e- 43      1.02  0.33  0.112 8.60e- 39 0       PRKCQ-AS1\n 6 0              5.57  0.996 0.215 0         1       S100A9   \n 7 0              5.48  0.975 0.121 0         1       S100A8   \n 8 0              3.81  0.909 0.059 0         1       LGALS2   \n 9 0              3.40  0.952 0.15  0         1       FCN1     \n10 3.89e-268      4.55  1     0.516 5.34e-264 1       LYZ      \n\nDoHeatmap(pbmc, features = top_n$gene) + NoLegend()"
  },
  {
    "objectID": "example_1.html#cell-type-identity-to-clusters",
    "href": "example_1.html#cell-type-identity-to-clusters",
    "title": "Example #1",
    "section": "Cell Type Identity To Clusters",
    "text": "Cell Type Identity To Clusters\nBlockquote:\n\nFortunately in the case of this data-set, we can use canonical markers to easily match the unbiased clustering to known cell types:\n\n\n\n\n\nKnown cell type markers\n\n\n\n\nnew.cluster.ids &lt;- c(\"Naive CD4 T\", \"CD14+ Mono\", \"Memory CD4 T\", \n                     \"B\", \"CD8 T\", \"FCGR3A+ Mono\",\n                    \"NK\", \"DC\", \"Platelet\")\nnames(new.cluster.ids) &lt;- levels(pbmc)\npbmc &lt;- RenameIdents(pbmc, new.cluster.ids)\nDimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5) + NoLegend()\n\n\n\n\n\nfile_path &lt;- paste0(\"./seurat_object_checkpoints/pbmc_sw1\",EGN,\"_final.rds\")\nsaveRDS_overwrite(file_path)\n# Done. See yah :)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RNA Seq Analysis",
    "section": "",
    "text": "Having experience of analyzing gene expression data with various tools from GeneSpring through edgeR and more recently having followed tutorials on Single-cell RNA-seq data analysis using Chipster (Seurat based workflows including SingleR, CellDex, CCA, RPCA [Chipster Tutorials, 2023]), my objective is to go deeper into single-cell analysis/programming with Seurat (directly with R/RStudio) to refine understanding and explore the many possibilities, using publicly available data-sets (since much of the data and software I used or developed over the past 7 years is proprietary)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About me"
  },
  {
    "objectID": "example_2.html",
    "href": "example_2.html",
    "title": "Example #2",
    "section": "",
    "text": "Some examples of non-proprietary analysis.\nWork in progress"
  }
]